<!DOCTYPE html>
<html>

<head>
    <title>Sound Demo</title>
    <link rel="stylesheet" type="text/css"
        href="https://cdn.jsdelivr.net/gh/bit101/quicksettings@3.0.3/quicksettings.css">
    <script type="text/javascript"
        src="https://cdn.jsdelivr.net/gh/bit101/quicksettings@3.0.3/quicksettings.js"></script>
    <!-- <script type="text/javascript" src="localstoragedemo.js"></script> -->
</head>

<body>
    <canvas id="canvas"></canvas>
</body>

</html>


<script>
    version = "NSD-QS" + 0.0002 //+ new Date(); // version number to control browser cache
    // var settings;
    var settings = null;


    window.onload = function () {

        if (localStorage.getItem(version) == null) { localStorage.clear(); } // clear local storage if version is different

        var count = -4;

        function countFunc() {
            console.log("count", ++count);
            if (count > 0) {

                // setTimeout(() => function () {
                window.location.reload()

                // }(), 0);
            };
            return true
        }
        countFunc();

        settings = QuickSettings.create(20, 20, "NSD-AI Sound Analysis Demo")
            .addRange("Overlap Factor", 0.01, 0.99, 0.5, 0.01, countFunc)
            .addRange("Probability Threshold", 0.01, 0.99, 0.5, 0.01, countFunc)
            .addRange("Speech Trigger Threshold", 0.01, 0.99, 0.8, 0.01, countFunc)
            .addBoolean("Spectrogram", true)
            .addBoolean("Embedding", false)
            .addText("Result", "Waiting. . .")
            .addColor("color", "#00FF00")
            .addHTML("Info", "This is demo of Sound Detection for NSD-AI.") // save settings in local storage
            .addHTML("Log", "Loading. . .") // save settings in local storage
            .saveInLocalStorage(version)
            ;
        // settings.setGlobalChangeHandler(countFunc);

    }


</script>


<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands"></script>

<script type="module">
    // When calling `create()`, you must provide the type of the audio input.
    // The two available options are `BROWSER_FFT` and `SOFT_FFT`.
    // - BROWSER_FFT uses the browser's native Fourier transform.
    // - SOFT_FFT uses JavaScript implementations of Fourier transform
    //   (not implemented yet).
    var recognizer = speechCommands.create('BROWSER_FFT', '18w');

    // Make sure that the underlying model and metadata are loaded via HTTPS
    // requests.
    await recognizer.ensureModelLoaded();

    // See the array of words that the recognizer is trained to recognize.
    console.log(recognizer.wordLabels());
    console.log(recognizer);
    // debugger

    // `listen()` takes two arguments:
    // 1. A callback function that is invoked anytime a word is recognized.
    // 2. A configuration object with adjustable fields such a
    //    - includeSpectrogram
    //    - probabilityThreshold
    //    - includeEmbedding


    recognizer.listen(result => {
        console.log(result)
        // console.log(result.scores[0])
        var maxNum = Math.max.apply(null, result.scores);
        var label = recognizer.wordLabels()[result.scores.indexOf(maxNum)]
        // debugger

        // console.log(maxNum, label, "| Background", result.scores[0])

        settings.setValue('color', "#ff0000");

        settings.setValue('Log', maxNum.toFixed(5) + " " + label + " <br> Background " + result.scores[0].toFixed(5));

        var myTimeout;

        function backgroundNoiseTimeout() {
            clearTimeout(myTimeout);
            myTimeout = setTimeout(function () {
                if (settings.getValuesAsJSON()["color"] !== '#0000ff') {
                    settings.setValue('Result', "Background Noise");
                    settings.setValue('color', "#0000ff")
                }
            }, 1000);
        }



        if (['_unknown_', '_background_noise_'].includes(label)) {
            settings.setValue('Result', "Background Noise");
            settings.setValue('color', "#0000ff")

        }
        else {

            if (maxNum > settings.getValue('Speech Trigger Threshold')) {
                settings.setValue('Result', "Speech Sound!!");
                backgroundNoiseTimeout()
            }

        }
        // debugger
        // - result.scores contains the probability scores that correspond to
        //   recognizer.wordLabels().
        // - result.spectrogram contains the spectrogram of the recognized word.
    }, {
        overlapFactor: settings.getValuesAsJSON()["Overlap Factor"] || 0.9, //second
        probabilityThreshold: settings.getValuesAsJSON()["Probability Threshold"] || 0.75,
        includeSpectrogram: settings.getValuesAsJSON()['Spectrogram'] || true,
        invokeCallbackOnNoiseAndUnknown: true
    });

    // // Stop the recognition in 10 seconds.
    // setTimeout(() => async function () {
    //     debugger;
    //     // recognizer.stopListening()
    //     recognizer = speechCommands.create('BROWSER_FFT', 'directional4w');
    //     await recognizer.ensureModelLoaded();
    //     console.log(recognizer.wordLabels());

    // }, 5e3);


</script>
